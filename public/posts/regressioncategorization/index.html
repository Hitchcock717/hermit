<!DOCTYPE html>
<html lang="en-us">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">
<meta itemprop="name" content="回归（Regression）与 分类（Categorization）">
<meta itemprop="description" content="分类与回归的区别 | 特性 | 分类（监督学习） | 回归 | | 输出类型 | 离散数据 | 连续数据 | | 目的 | 寻找决策边界 | 找到最优拟合 | | 评价方法 | 精度、混淆矩">
<meta itemprop="datePublished" content="2019-11-15T17:31:56+00:00" />
<meta itemprop="dateModified" content="2019-11-15T17:31:56+00:00" />
<meta itemprop="wordCount" content="1566">



<meta itemprop="keywords" content="Note,Machine Learning," />
<meta property="og:title" content="回归（Regression）与 分类（Categorization）" />
<meta property="og:description" content="分类与回归的区别 | 特性 | 分类（监督学习） | 回归 | | 输出类型 | 离散数据 | 连续数据 | | 目的 | 寻找决策边界 | 找到最优拟合 | | 评价方法 | 精度、混淆矩" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hitchcock717.github.io/posts/regressioncategorization/" />
<meta property="article:published_time" content="2019-11-15T17:31:56+00:00" />
<meta property="article:modified_time" content="2019-11-15T17:31:56+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="回归（Regression）与 分类（Categorization）"/>
<meta name="twitter:description" content="分类与回归的区别 | 特性 | 分类（监督学习） | 回归 | | 输出类型 | 离散数据 | 连续数据 | | 目的 | 寻找决策边界 | 找到最优拟合 | | 评价方法 | 精度、混淆矩"/>

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/favicon.ico">

	<title>回归（Regression）与 分类（Categorization）</title>
	<link rel="stylesheet" href="https://hitchcock717.github.io/css/style.min.eac77496566fd7d5768fd650ddb0b2b181ca6a2d7c5fdd6fe6b8ba4bf47e566f.css" integrity="sha256-6sd0llZv19V2j9ZQ3bCysYHKai18X91v5ri6S/R+Vm8=" crossorigin="anonymous">
	
</head>

<body id="page">
	
	<header id="site-header" class="animated slideInUp">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="https://hitchcock717.github.io">Darth Vader</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					
				<a href="https://hitchcock717.github.io/posts/">Posts</a>
				<a href="https://hitchcock717.github.io/about-hugo/">About</a>

				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<span class="hdr-social hide-in-mobile"><a href="https://github.com/Hitchcock717" target="_blank" rel="noopener me" title="Github"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></span><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="https://hitchcock717.github.io/posts/">Posts</a></li>
			<li><a href="https://hitchcock717.github.io/about-hugo/">About</a></li>
		</ul>
	</div>


	<main class="site-main section-inner animated fadeIn faster">
		<article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Nov 15, 2019</span></div>
				<h1>回归（Regression）与 分类（Categorization）</h1>
			</header>
			<div class="content">
				<h2 id="分类与回归的区别">分类与回归的区别<a href="#分类与回归的区别" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<div class="highlight"><pre class="chroma"><code class="language-markdown" data-lang="markdown">|   特性   | 分类（监督学习） |           回归            |
| 输出类型  |    离散数据    |          连续数据          |
|   目的 	 |   寻找决策边界  |         找到最优拟合        |
| 评价方法  | 精度、混淆矩阵  | SSE(平方误差总和)、拟合优度   |
</code></pre></div><p><a href="https://www.zhihu.com/people/dataju">转自知乎赵熙</a></p>
<p><strong>分类模型和回归模型本质一样，分类模型可将回归模型的输出离散化（下面例子1. 2. 4. 5.），回归模型也可将分类模型的输出连续化（下面例子3.）</strong></p>
<p>举几个例子:</p>
<ol>
<li>
<p>Logistic Regression 和 Linear Regression：</p>
</li>
<li>
<ol>
<li><strong>Linear Regression</strong>： 输出一个标量 wx+b，这个值是连续值，所以可以用来处理<strong>回归</strong>问题</li>
<li><strong>Logistic Regression</strong>：把上面的 wx+b 通过 sigmoid 函数映射到(0,1)上，并划分一个阈值，大于阈值的分为一类，小于等于分为另一类，可以用来处理<strong>二分类</strong>问题</li>
<li>更进一步：对于N分类问题，则是先得到N组w值不同的 wx+b，然后归一化，比如用 softmax 函数，最后变成N个类上的概率，可以处理<strong>多分类</strong>问题</li>
</ol>
</li>
<li>
<p>Support Vector Regression 和 Support Vector Machine:</p>
</li>
<li>
<ol>
<li><strong>SVR</strong>：输出 wx+b，即某个样本点到分类面的距离，是连续值，所以是<strong>回归</strong>模型</li>
<li><strong>SVM</strong>：把这个距离用 sign(·) 函数作用，距离为正(在超平面一侧)的样本点是一类，为负的是另一类，所以是<strong>分类</strong>模型</li>
</ol>
</li>
<li>
<p><strong>Naive Bayes</strong> 用于分类 和 回归:</p>
</li>
<li>
<ol>
<li>用于分类：y是离散的类别，所以得到离散的 p(y|x)，给定 x ，输出每个类上的概率</li>
<li>用于回归：对上面离散的 p(y|x)求期望 ΣyP(y|x)，就得到连续值。但因为此时y本身是连续的值，所以最地道的做法是，得到连续的概率密度函数p(y|x)，然后再对y求期望。参考 <a href="https://link.zhihu.com/?target=http%3A//www.cs.waikato.ac.nz/~eibe/pubs/nbr.pdf">http://www.cs.waikato.ac.nz/~eibe/pubs/nbr.pdf</a></li>
</ol>
</li>
<li>
<p><strong>前馈神经网络(如 CNN 系列)</strong> 用于 分类 和 回归:</p>
</li>
<li>
<ol>
<li>用于回归：最后一层有m个神经元，每个神经元输出一个标量，m个神经元的输出可以看做向量 v，现全部连到一个神经元上，则这个神经元输出 wv+b，是一个连续值，可以处理回归问题，跟上面 Linear Regression 思想一样</li>
<li>用于N分类：现在这m个神经元最后连接到 N 个神经元，就有 N 组w值不同的 wv+b，同理可以归一化（比如用 softmax ）变成 N个类上的概率（补充一下，如果不用 softmax，而是每个 wx+b 用一个 sigmoid，就变成<strong>多标签</strong>问题，跟多分类的区别在于，样本可以被打上多个标签）</li>
</ol>
</li>
<li>
<p><strong>循环神经网络(如 RNN 系列)</strong> 用于分类 和 回归：</p>
</li>
<li>
<ol>
<li>用于回归 和 分类： 跟 CNN 类似，输出层的值 y = wv+b，可做分类可做回归，只不过区别在于，RNN 的输出跟时间有关，即输出的是 {y(t), y(t+1),&hellip;}序列（关于时间序列，见下面的更新）</li>
</ol>
</li>
</ol>
<p>上面的例子其实都是从 prediction 的角度举例的，如果从 training 角度来看，分类模型和回归模型的目标函数不同，分类常见的是 log loss, hinge loss, 而回归是 square loss（关于 loss function，又是另一个story了，在此不展开了）</p>
<p>==== 进一步思考后的<strong>重要更新，谈谈时间序列模型</strong> ========</p>
<p>上面的例子 1~4 解决的是常见的分类/回归问题，而例5 解决的是 时间序列问题。</p>
<ol>
<li>
<p>上面例1~4 的模型只适用于：这些样本的 y，没有时间上的相关性，比如：</p>
</li>
<li>
<ol>
<li>人脸识别（分类问题），输入 x 是人脸的图像矩阵，识别目标 y 是人的ID，离散值，显然人与人的ID没有时间上的关系</li>
<li>人脸年龄预测（回归问题），输入 x 还是人脸图像矩阵，识别目标 y 是人的年龄，连续值，显然人与人之间的年龄亦没有时间上的关系</li>
</ol>
</li>
<li>
<p>而当这些样本的 y 在时间上有相关性时，就变成了 时间序列问题，如果我们依然用非时间序列的方法来处理，就割裂了y的时间相关性，所以常见手段是用例5提到的RNN，（当然，还有 HMM, CRF 这些）但注意别用统计学里面那些愚蠢的 AR 模型（参考我的回答 <a href="https://www.zhihu.com/question/31833683/answer/152064596">时间序列建模问题，如何准确的建立时间序列模型？ - 知乎用户的回答 - 知乎</a>）。应用场景：</p>
</li>
<li>
<ol>
<li>NLP 里的命名体识别（分类问题），输入是一句话，可以看做是由单词组成的时间序列（准确说是: 事件序列），输出是每个单词所属的标签</li>
<li>气温预测（回归问题），输入是历史时间的气温记录，输出是未来1天或多天的气温</li>
</ol>
</li>
</ol>
<p>总结一下，我认为，机器学习模型(有监督)本质是：</p>
<blockquote>
<p>对一系列样本 <img src="https://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="(x,y)"> 构建 <img src="https://www.zhihu.com/equation?tex=f%28x%29%5Crightarrow+y" alt="f(x)\rightarrow y"> 的映射</p>
</blockquote>
<p>所以，对于时间序列问题，其实是构建一个 <img src="https://www.zhihu.com/equation?tex=f%28x_t%2Cx_%7Bt%2B1%7D%2C...%2Cx_%7Bt%2Bdt%7D%29%5Crightarrow+y_%7Bt%2B1%7D%2C...%2Cy_%7Bt%2Bdt%2B1%7D" alt="f(x_t,x_{t+1},&hellip;,x_{t+dt})\rightarrow y_{t+1},&hellip;,y_{t+dt+1}"> 的映射关系</p>

			</div>
			<hr class="post-end">
			<footer class="post-info">
				<p>
					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://hitchcock717.github.io/tags/note">Note</a></span><span class="tag"><a href="https://hitchcock717.github.io/tags/machine-learning">Machine Learning</a></span>
				</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>1566 Words</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2019-11-16 01:31 &#43;0800</p>
			</footer>
		</article>
		<div class="post-nav thin">
			<a class="next-post" href="https://hitchcock717.github.io/posts/html_dom-learning/">
				<span class="post-nav-label"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left"><line x1="19" y1="12" x2="5" y2="12"></line><polyline points="12 19 5 12 12 5"></polyline></svg>&nbsp;Newer</span><br><span>HTML之DOM节点树</span>
			</a>
			<a class="prev-post" href="https://hitchcock717.github.io/posts/fiddler-mono-mac/">
				<span class="post-nav-label">Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><br><span>爬虫之Fiddler-Mono代理工具</span>
			</a>
		</div>
		<div id="comments" class="thin">
</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2021 <a href="https://hitchcock717.github.io">Hitchcock</a> &#183; <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0</a></p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a> &#183; <a href="https://hitchcock717.github.io/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a>
		</p>
	</footer>



	<script src="https://hitchcock717.github.io/js/bundle.min.4a9a0ac3d2217822c7865b4161e6c2a71de1d70492264337755427898dd718f6.js" integrity="sha256-SpoKw9IheCLHhltBYebCpx3h1wSSJkM3dVQniY3XGPY=" crossorigin="anonymous"></script>
	

</body>

</html>
