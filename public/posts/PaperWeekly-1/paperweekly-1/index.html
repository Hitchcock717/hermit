<!DOCTYPE html>
<html lang="en-us">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">
<meta itemprop="name" content="PaperWeekly-1: nlp中的实体关系抽取方法总结笔记">
<meta itemprop="description" content="The source comes from: https://zhuanlan.zhihu.com/p/77868938 Catagory Q1：与联合抽取对比，Pipeline方法有哪些缺点？ Q2：NER除了LSTM&#43;CRF，还有哪些解码方式？如何解决嵌套实体问题？">
<meta itemprop="datePublished" content="2020-03-24T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-03-24T00:00:00+00:00" />
<meta itemprop="wordCount" content="5172">



<meta itemprop="keywords" content="NLP," />
<meta property="og:title" content="PaperWeekly-1: nlp中的实体关系抽取方法总结笔记" />
<meta property="og:description" content="The source comes from: https://zhuanlan.zhihu.com/p/77868938 Catagory Q1：与联合抽取对比，Pipeline方法有哪些缺点？ Q2：NER除了LSTM&#43;CRF，还有哪些解码方式？如何解决嵌套实体问题？" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hitchcock717.github.io/posts/paperweekly-1/paperweekly-1/" />
<meta property="article:published_time" content="2020-03-24T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-03-24T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="PaperWeekly-1: nlp中的实体关系抽取方法总结笔记"/>
<meta name="twitter:description" content="The source comes from: https://zhuanlan.zhihu.com/p/77868938 Catagory Q1：与联合抽取对比，Pipeline方法有哪些缺点？ Q2：NER除了LSTM&#43;CRF，还有哪些解码方式？如何解决嵌套实体问题？"/>

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/favicon.ico">

	<title>PaperWeekly-1: nlp中的实体关系抽取方法总结笔记</title>
	<link rel="stylesheet" href="https://hitchcock717.github.io/css/style.min.eac77496566fd7d5768fd650ddb0b2b181ca6a2d7c5fdd6fe6b8ba4bf47e566f.css" integrity="sha256-6sd0llZv19V2j9ZQ3bCysYHKai18X91v5ri6S/R+Vm8=" crossorigin="anonymous">
	
</head>

<body id="page">
	
	<header id="site-header" class="animated slideInUp">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="https://hitchcock717.github.io">Darth Vader</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					
				<a href="https://hitchcock717.github.io/posts/">Posts</a>
				<a href="https://hitchcock717.github.io/about-hugo/">About</a>

				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<span class="hdr-social hide-in-mobile"><a href="https://github.com/Hitchcock717" target="_blank" rel="noopener me" title="Github"><svg xmlns="http://www.w3.org/2000/svg" class="feather" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></span><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="https://hitchcock717.github.io/posts/">Posts</a></li>
			<li><a href="https://hitchcock717.github.io/about-hugo/">About</a></li>
		</ul>
	</div>


	<main class="site-main section-inner animated fadeIn faster">
		<article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Mar 24, 2020</span></div>
				<h1>PaperWeekly-1: nlp中的实体关系抽取方法总结笔记</h1>
			</header>
			<div class="content">
				<blockquote>
<p>The source comes from: <a href="https://zhuanlan.zhihu.com/p/77868938">https://zhuanlan.zhihu.com/p/77868938</a></p>
</blockquote>
<h1 id="catagory">Catagory<a href="#catagory" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<ol>
<li><a href="#Q1%EF%BC%9A%E4%B8%8E%E8%81%94%E5%90%88%E6%8A%BD%E5%8F%96%E5%AF%B9%E6%AF%94%EF%BC%8CPipeline%E6%96%B9%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B%E7%BC%BA%E7%82%B9%EF%BC%9F">Q1：与联合抽取对比，Pipeline方法有哪些缺点？</a></li>
<li><a href="#Q2%EF%BC%9ANER%E9%99%A4%E4%BA%86LSTM+CRF%EF%BC%8C%E8%BF%98%E6%9C%89%E5%93%AA%E4%BA%9B%E8%A7%A3%E7%A0%81%E6%96%B9%E5%BC%8F%EF%BC%9F%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%B5%8C%E5%A5%97%E5%AE%9E%E4%BD%93%E9%97%AE%E9%A2%98%EF%BC%9F">Q2：NER除了LSTM+CRF，还有哪些解码方式？如何解决嵌套实体问题？</a></li>
<li><a href="#Q3%EF%BC%9APipeline%E4%B8%AD%E7%9A%84%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%E6%9C%89%E5%93%AA%E4%BA%9B%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%EF%BC%9F%E5%A6%82%E4%BD%95%E5%BA%94%E7%94%A8%E5%BC%B1%E7%9B%91%E7%9D%A3%E5%92%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%88%B6%EF%BC%9F%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%E9%AB%98%E5%A4%8D%E6%9D%82%E5%BA%A6%E9%97%AE%E9%A2%98%E3%80%81%E8%BF%9B%E8%A1%8Cone-pass%E5%85%B3%E7%B3%BB%E5%88%86%E7%B1%BB%EF%BC%9F">Q3：Pipeline中的关系分类有哪些常用方法？如何应用弱监督和预训练机制？怎么解决高复杂度问题、进行one-pass关系分类？</a></li>
<li><a href="#Q4%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E5%85%B3%E7%B3%BB%E9%87%8D%E5%8F%A0&amp;%E5%A4%8D%E6%9D%82%E5%85%B3%E7%B3%BB%E9%97%AE%E9%A2%98%EF%BC%9F">Q4：什么是关系重叠&amp;复杂关系问题？</a></li>
<li><a href="#Q5%EF%BC%9A%E8%81%94%E5%90%88%E6%8A%BD%E5%8F%96%E9%9A%BE%E7%82%B9%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9F%E8%81%94%E5%90%88%E6%8A%BD%E5%8F%96%E6%80%BB%E4%BD%93%E4%B8%8A%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E6%B3%95%EF%BC%9F%E5%90%84%E6%9C%89%E5%93%AA%E4%BA%9B%E7%BC%BA%E7%82%B9%EF%BC%9F">Q5：联合抽取难点在哪里？联合抽取总体上有哪些方法？各有哪些缺点？</a></li>
<li><a href="#Q6%EF%BC%9A%E4%BB%8B%E7%BB%8D%E5%9F%BA%E4%BA%8E%E5%85%B1%E4%BA%AB%E5%8F%82%E6%95%B0%E7%9A%84%E8%81%94%E5%90%88%E6%8A%BD%E5%8F%96%E6%96%B9%E6%B3%95%EF%BC%9F">Q6：介绍基于共享参数的联合抽取方法？</a></li>
<li><a href="#Q7%EF%BC%9A%E4%BB%8B%E7%BB%8D%E5%9F%BA%E4%BA%8E%E8%81%94%E5%90%88%E8%A7%A3%E7%A0%81%E7%9A%84%E8%81%94%E5%90%88%E6%8A%BD%E5%8F%96%E6%96%B9%E6%B3%95%EF%BC%9F">Q7：介绍基于联合解码的联合抽取方法？</a></li>
<li><a href="#Q8%EF%BC%9A%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%9A%84%E5%89%8D%E6%B2%BF%E6%8A%80%E6%9C%AF%E5%92%8C%E6%8C%91%E6%88%98%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E4%BD%8E%E8%B5%84%E6%BA%90%E5%92%8C%E5%A4%8D%E6%9D%82%E6%A0%B7%E6%9C%AC%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%EF%BC%9F%E5%A6%82%E4%BD%95%E5%BA%94%E7%94%A8%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">Q8：实体关系抽取的前沿技术和挑战有哪些？如何解决低资源和复杂样本下的实体关系抽取？如何应用图神经网络</a></li>
</ol>
<hr>
<p><img src="paper-structure.jpg" alt="抽取任务概述"></p>
<h1 id="q1与联合抽取对比pipeline方法有哪些缺点">Q1：与联合抽取对比，Pipeline方法有哪些缺点？<a href="#q1与联合抽取对比pipeline方法有哪些缺点" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<h3 id="知识点事件抽取-pipeline法">知识点：事件抽取-Pipeline法<a href="#知识点事件抽取-pipeline法" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>化整为零，搞一堆分类器：Trigger Classifier, Argument Classifier&hellip;缺点很明显，由于流程过长，各自为政，导致误差积累。</p>
<h1 id="q2ner除了lstmcrf还有哪些解码方式如何解决嵌套实体问题">Q2：NER除了LSTM+CRF，还有哪些解码方式？如何解决嵌套实体问题？<a href="#q2ner除了lstmcrf还有哪些解码方式如何解决嵌套实体问题" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<h3 id="关于lstmhttpsblogcsdnnetjerr__yarticledetails58598296"><a href="https://blog.csdn.net/Jerr__y/article/details/58598296">关于LSTM</a><a href="#关于lstmhttpsblogcsdnnetjerr__yarticledetails58598296" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>先得提到著名的RNN，“有记忆”的神经网络。可以把 RNNs 看成是一个普通的网络做了多次复制后叠加在一起组成的。每一网络会把它的输出传递到下一个网络中。我们可以把 RNNs 在时间步上进行展开，就得到下图这样：<img src="RNN.png" alt="RNN">
LSTM是特殊的、更好用的RNN，尤其对于上下文预测间隔较长的情况，LSTM很有用。相比RNN中间为单一的tanh层，LSTM更复杂。</p>
<h3 id="核心思想">核心思想<a href="#核心思想" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<ul>
<li>利用cell传输信息</li>
<li>利用门过滤信息：具体通过sigmoid+逐点相乘的方法</li>
<li>sigmoid相当于bool值，0为否，1为是</li>
<li>门结构包括传入门，遗忘门，输出门</li>
<li>遗忘门(用来保留信息)，传入门(决定让哪些新信息加入cell)</li>
</ul>
<h3 id="softmax函数">Softmax函数<a href="#softmax函数" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>用于多分类，将多个神经元映射进（0，1）区间，按概率比较。大概公式就是这样：
<img src="Softmax.png" alt="Softmax公式"></p>
<h3 id="其他激活函数httpsblogcsdnnetshenxiaoming77articledetails76795445"><a href="https://blog.csdn.net/shenxiaoming77/article/details/76795445">其他激活函数</a><a href="#其他激活函数httpsblogcsdnnetshenxiaoming77articledetails76795445" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p><img src="activate.jpg" alt="Sigmoid，Tahn">
tahn将一个实数输入映射到[-1,1]范围内，如上图（右）所示。当输入为0时，tanh函数输出为0，符合我们对激活函数的要求。然而，tanh函数也存在梯度饱和问题，导致训练效率低下。
<img src="ReLu.jpg" alt="ReLu">
相比sigmoid和tanh函数，Relu激活函数的优点在于：</p>
<blockquote>
<p>梯度不饱和。梯度计算公式为：。因此在反向传播过程中，减轻了梯度弥散的问题，神经网络前几层的参数也可以很快的更新。
计算速度快。正向传播过程中，sigmoid和tanh函数计算激活值时需要计算指数，而Relu函数仅需要设置阈值。
因此，Relu激活函数可以极大地加快收敛速度，相比tanh函数，收敛速度可以加快6倍（如上图（右）所示）。</p>
</blockquote>
<h3 id="实体重叠问题">实体重叠问题<a href="#实体重叠问题" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>文章用《叶圣陶散文选集》说明该问题，作者和作品两个实体混淆。解决办法：实体抽取解码</p>
<h3 id="办法1序列标注softmax--crf">办法1：序列标注（Softmax + CRF）<a href="#办法1序列标注softmax--crf" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>本质是token-level的多分类问题，token指的是字符级别的概念；相比segment-level，范围更大，说的就是词切分，也就是分词
CRF：给序列中的每一个token进行分类，好处是加入了上下文的联系。</p>
<h3 id="对于分词边界错误的改进方法-latticelstmcrfhttpsblogcsdnnetqq_32728345articledetails81264853"><a href="https://blog.csdn.net/qq_32728345/article/details/81264853">对于分词边界错误的改进方法-LatticeLSTM+CRF</a><a href="#对于分词边界错误的改进方法-latticelstmcrfhttpsblogcsdnnetqq_32728345articledetails81264853" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p><img src="LatticeLSTM.png" alt="示意图">
如图所示，先将每个字符切分开，再用红色的cell表示中文词汇，形成网格结构。
词汇边界通常为实体边界，根据大量语料构建词典，若当前字符与之前字符构成词汇，则从这些词汇中提取信息，联合更新记忆状态。
jieba的全切分模式和搜索引擎模式，可以将所有组合列出；若遇到以相同词结尾的词汇时，会根据预先准备的字、词典，训练字词级别的向量。</p>
<h2 id="办法1的缺陷及改进">办法1的缺陷及改进<a href="#办法1的缺陷及改进" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>序列标注采取BILOU（Begin, Inside, Last, Outside, Unit)）标注框架，每一个token只能属于一种，不能解决重叠实体问题。
改进1：Softmax——&gt;Sigmoid（0/1表达）
改进2：增加标签，合并
两种方式本质上都是给实体增加说明信息，不同的是一个是用数字结构，一个是用标签信息。</p>
<h2 id="办法2指针网络pointernethttpszhuanlanzhihucomp48959800">办法2：<a href="https://zhuanlan.zhihu.com/p/48959800">指针网络（PointerNet）</a><a href="#办法2指针网络pointernethttpszhuanlanzhihucomp48959800" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>先说seq2seq，常用在MT中做序列对齐。其中，加入Attention机制后，由于对encoder的隐含状态加权拼接至decoder，实现软对齐，效果提升。
PointerNet是Attention机制的简化，用于解决类似寻找凸包问题。对于凸包问题的示例，如下：
<img src="Convex.jpg" alt="凸包问题">
传统seq2seq模型解决方式是输入四个点的坐标，比如input list = [start, 1, 2, 3, 4, end]，则output list = [start, 1, 4, 2, 1, end]
一旦list长度改变，则无法预测大于4的数字，而PointerNet可以。因为添加了指针，所以output list跟随input list变动而变动。而为什么说PointerNet是Attention机制的衍生，是因为Attention作用在encoder的weight变成了pointer，如想对某个元素增加weight，则直接point该元素即可。
换句话说，传统带有注意力机制的seq2seq模型输出的是针对输出词汇表的一个概率分布，而Pointer Networks输出的则是针对输入文本序列的概率分布。</p>
<h3 id="pointernet在ner中">PointerNet在NER中<a href="#pointernet在ner中" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<ul>
<li>MRC-QA + Single-Layer-PointerNet
这种方式目的在于将原文本构建成完成的query，在补充的后续query部分加入先验语义知识。根据不同的语义，使用一层PointerNet指明头尾指针。</li>
<li>Multiple-Layer-PointerNet
这种方式弥补了单层只能抽取单类型实体的不足，添加了多层label。
简单来说，PointerNet仍具有收敛速度慢、计算量大的缺点。</li>
</ul>
<h2 id="办法3片段排列分类">办法3：片段排列+分类<a href="#办法3片段排列分类" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>扩大了从token-level抽取的概念，将重点放在span-level。这种方式将含T个token的文本按固定顺序一一列出，如叶，叶圣，叶圣陶&hellip;缺点是对于长文本，一是无意义的样本较多，需削减；二是计算量大。</p>
<h1 id="q3pipeline中的关系分类有哪些常用方法如何应用弱监督和预训练机制怎么解决高复杂度问题进行one-pass关系分类">Q3：Pipeline中的关系分类有哪些常用方法？如何应用弱监督和预训练机制？怎么解决高复杂度问题、进行one-pass关系分类？<a href="#q3pipeline中的关系分类有哪些常用方法如何应用弱监督和预训练机制怎么解决高复杂度问题进行one-pass关系分类" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<ul>
<li>模板匹配：一是人工判断上下位关系；二是统计模板，利用search engine如维基百科里的知识图谱，保留置信度高的</li>
<li>半监督学习：
（1）自举（bootstrapping），利用少量种子集合举一反三。优点是构建成本低，缺点是造成语义漂移。对于语义漂移的解释如下，<a href="https://blog.csdn.net/u012485480/article/details/80208821">参考</a></li>
</ul>
<blockquote>
<p>众所周知的是bootstrapping通常会获取与种子无关的实例。例如对于任务“从网络语料库中收集常见景点名称”。给定词语“Geneva”(日内瓦)和“Bali”(巴黎)作为种子实例，bootstrapping最终将学习成通用模式如“pictures”和“photos”，这些与其他不相关实例同时出现。随后的迭代可能会获得与这些通用模式共同出现的频繁词语，如“Britney Spears”，这种现象被称为语义漂移。</p>
</blockquote>
<p>（2）远程监督，假定某实体对满足某个关系，则包含该实体对的所有句子（称为Bag）都可能满足该关系。但实际情况远非如此，所以有如下改进：</p>
<ul>
<li>多示例学习：对包含实体对的句子进行分类，如PCNNs模型。针对远程监督中的wrong label problem，采用多示例学习的方式从训练集中抽取置信度较高的训练样例模型，一般构建过程包括word embeddings——&gt;convolution——&gt;pooling——&gt;Softmax multi-label output——&gt;multi-example learning。后续加入Attention机制，出现了APCNNs模型。相比PCNNs，在pooling层后，softmax之前加入基于句子级别的attention机制（能够根据特定关系为实体对的每个句子分配权重，通过不断学习使得有效句子获得高权重，有噪音的句子获得低权重。<a href="https://www.jianshu.com/p/bd324b312903">参考</a></li>
<li>强化学习：优化Bag掺杂大量噪声的情况，包括样例选择器和关系分类器。前者负责从样例中筛选高质量句子，后者向前者做出反馈，提供更优的选择策略。</li>
<li>预训练机制：无需任何知识库和人工标注，将实体作为“blank”标识符进行填充；包含同样实体对的句子为正样本，反之为负样本
（3）监督学习，主要分为基于特征（定义特征集合）、核函数（无需定义特征集合，核函数只是用来计算映射到高维空间之后的内积）和深度学习（主要贡献在于对Bag只需one-pass输入即可进行多个关系分类）。</li>
</ul>
<h1 id="q4什么是关系重叠复杂关系问题">Q4：什么是关系重叠&amp;复杂关系问题？<a href="#q4什么是关系重叠复杂关系问题" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p><img src="Relationmap.jpg" alt="关系图示例"></p>
<ul>
<li>a：正常关系问题</li>
<li>b：关系重叠问题，一对多。如“张学友演唱过《吻别》《在你身边》”中，存在2种关系：「张学友-歌手-吻别」和「张学友-歌手-在你身边」</li>
<li>c：关系重新问题，一对实体存在多种关系。如“周杰伦作曲并演唱《七里香》”中，存在2种关系：「周杰伦-歌手-七里香」和「周杰伦-作曲-七里香」</li>
<li>d：复杂关系问题，由实体重叠导致。如《叶圣陶散文选集》中，叶圣陶-作品-叶圣陶散文选集；</li>
<li>e：复杂关系问题，关系交叉导致。如“张学友、周杰伦分别演唱过《吻别》《七里香》”，「张学友-歌手-吻别」和「周杰伦-歌手-七里香」</li>
</ul>
<h1 id="q5联合抽取难点在哪里联合抽取总体上有哪些方法各有哪些缺点">Q5：联合抽取难点在哪里？联合抽取总体上有哪些方法？各有哪些缺点？<a href="#q5联合抽取难点在哪里联合抽取总体上有哪些方法各有哪些缺点" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>联合抽取模型分类：</p>
<ul>
<li>共享参数（通过共享参数（共享输入特征或者内部隐层状态）实现联合，此种方法对子模型没有限制，但是由于使用独立的解码算法，导致实体模型和关系模型之间交互不强。）</li>
<li>联合解码（需要对子模型特征的丰富性以及联合解码的精确性之间做权衡）
需要做的：需要一个方法可以同时考虑一个句子中所有实体、实体与关系、关系与关系之间的交互。</li>
</ul>
<h1 id="q6介绍基于共享参数的联合抽取方法">Q6：介绍基于共享参数的联合抽取方法？<a href="#q6介绍基于共享参数的联合抽取方法" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p><img src="Papers.jpg" alt="主要的研究方法">
在联合抽取中的实体和关系抽取的解码方式与Q2中的实体抽取的解码方式基本一致，主要包括：序列标注CRF/SoftMax、指针网络、分类SoftMax、Seq2Seq等。基于共享参数的联合抽取，实体抽取loss会与关系抽取loss相加。</p>
<h1 id="q7介绍基于联合解码的联合抽取方法">Q7：介绍基于联合解码的联合抽取方法？<a href="#q7介绍基于联合解码的联合抽取方法" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>简单了解三种统一实体和关系的标注框架：</p>
<ul>
<li>用关系标签进行BIOES标注，head实体序号为1，tail实体序号为2。但该框架只能对实体在某个关系中进行表示，而对多关系无用</li>
<li>对n个token的句子有n个标注框架，采用BIES标注，用CRF解码。该框架复杂度自然很高了。</li>
<li>百度PaddlePaddle的SPO标注框架，这个挺有意思。
<img src="PaddlePaddle.jpg" alt="PaddlePaddle标注框架"></li>
<li>使用方法的是token level 的多label分类，即每一个token对应多个label。</li>
<li>标注框架十分巧妙，如上图示例中形成的2个spo三元组，「王雪纯-配音-晴雯」和「王雪纯-配音-红楼梦」，存在两个关系「配音-人物」和「配音-作品」，多label标签就以关系标签建立。</li>
<li>问题还在于对实体重叠关系抽取、多重同类关系无用，需引入后处理逻辑。</li>
</ul>
<h1 id="q8实体关系抽取的前沿技术和挑战有哪些如何解决低资源和复杂样本下的实体关系抽取如何应用图神经网络">Q8：实体关系抽取的前沿技术和挑战有哪些？如何解决低资源和复杂样本下的实体关系抽取？如何应用图神经网络<a href="#q8实体关系抽取的前沿技术和挑战有哪些如何解决低资源和复杂样本下的实体关系抽取如何应用图神经网络" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<ol>
<li>pipeline中的NER
<strong>实体重叠问题 ——&gt; 词典+规则</strong></li>
<li>关系分类问题
降低计算复杂度，拒绝重复编码句子，而是one-pass。<strong>在低资源场景下，采取远程监督的方法确实可以自动进行语料构建，但其中针对样本噪音的降噪方法是否还有提升空间？降噪方法能否做到与模型无关，是否可以借鉴图像分类中很有效的置信学习呢?</strong></li>
<li>联合抽取
难点是如何加强实体模型和关系模型之间的交互，怎么对需要对子模型特征的丰富性以及联合解码的精确性之间做权衡？</li>
<li>低资源和复杂样本问题
对于少次关系学习问题：他们提出了FewRel 2.0，在原版数据集FewRel的基础上增加了以下两大挑战：领域迁移（domain adaptation）和“以上都不是”检测（none-of-the-above detection）。
对于文档级别的关系抽取问题：提出了DocRED数据集[42]，是一个大规模的人工标注的文档级关系抽取数据集，文档级关系抽取任务要求模型具有强大的模式识别、逻辑推理、指代推理和常识推理能力。</li>
</ol>
<h1 id="参考文献">参考文献<a href="#参考文献" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h1>
<p>以下列举原文档的参考，以供日后慢慢研读。</p>
<p>Hierarchically-Refined Label Attention Network for Sequence Labeling <a href="https://arxiv.org/pdf/1908.08676.pdf">https://arxiv.org/pdf/1908.08676.pdf</a>
Chinese NER Using Lattice LSTM <a href="https://arxiv.org/pdf/1805.02023.pdf">https://arxiv.org/pdf/1805.02023.pdf</a>
abNeural Architectures for Nested NER through Linearization
Nested named entity recognition revisited.
abA Unified MRC Framework for Named Entity Recognition <a href="https://arxiv.org/pdf/1910.11476.pdf">https://arxiv.org/pdf/1910.11476.pdf</a>
<a href="https://zhuanlan.zhihu.com/p/89019478">https://zhuanlan.zhihu.com/p/89019478</a>
abcdSpan-Level Model for Relation Extraction <a href="https://www.aclweb.org/anthology/P19-1525.pdf">https://www.aclweb.org/anthology/P19-1525.pdf</a>
abDistant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks. EMNLP
Selective Attention over Instances (Lin 2016)
Relation Extraction with Multi-instance Multi-label Convolutional Neural Networks.
Distant Supervision for Relation Extraction with Sentence-Level Attention and Entity Descriptions
Reinforcement Learning for Relation Classification from Noisy Data
abcMatching the Blanks: Distributional Similarity for Relation Learning <a href="https://arxiv.org/pdf/1906.03158.pdf">https://arxiv.org/pdf/1906.03158.pdf</a>
abExtracting Multiple-Relations in One-Pass with Pre-Trained Transformers
abcdSimultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction <a href="https://www.aclweb.org/anthology/N18-1080.pdf">https://www.aclweb.org/anthology/N18-1080.pdf</a>
abc基于深度学习的联合实体关系抽取 <a href="http://www.czsun.site/publications/thesis.pdf">http://www.czsun.site/publications/thesis.pdf</a>
End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures <a href="https://www.aclweb.org/anthology/P16-1105.pdf">https://www.aclweb.org/anthology/P16-1105.pdf</a>
Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees <a href="https://pdfs.semanticscholar.org/bbbd/45338fbd85b0bacf23918bb77107f4cfb69e.pdf?_ga=2.119149259.311990779.1584453795-1756505226.1584453795">https://pdfs.semanticscholar.org/bbbd/45338fbd85b0bacf23918bb77107f4cfb69e.pdf?_ga=2.119149259.311990779.1584453795-1756505226.1584453795</a>
Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism
abJoint entity recognition and relation extraction as a multi-head selection problem
BERT-Based Multi-Head Selection for Joint Entity-Relation Extraction
Adversarial training for multi-context joint entity and relation extraction
abJoint Extraction of Entities and Relations Based on a Novel Decomposition Strategy
Entity-Relation Extraction as Multi-Turn Question Answering <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1905.05529.pdf">https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1905.05529.pdf</a>
abcdhttps://zhuanlan.zhihu.com/p/65870466
Span-based Joint Entity and Relation Extraction with Transformer Pre-training  <a href="https://arxiv.org/pdf/1909.07755.pdf">https://arxiv.org/pdf/1909.07755.pdf</a>
Joint inference for fine-grained opinion extraction
Investigating lstms for joint extraction of opinion entitiesandrelations.
Incremental joint extraction of entity mentions and relations.
End-to-end neural relation extrac- tion with global optimization.
Jointextractionofentities and relations based on a novel graph scheme
Joint extraction of entities and relations based on a novel tagging scheme. <a href="https://arxiv.org/pdf/1706.05075.pdf">https://arxiv.org/pdf/1706.05075.pdf</a>
Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling
abhttps://github.com/PaddlePaddle/Research/tree/master/KG/DuIE_Baseline
Confident Learning: Estimating Uncertainty in Dataset Labels
Graph Neural Networks with Generated Parameters for Relation
GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction
Attention Guided Graph Convolutional Networks for Relation Extraction
Joint Type Inference on Entities and Relations via Graph Convolutional Networks
abhttps://www.zhihu.com/search?type=content&amp;q=%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96
FewRel 2.0: Towards More Challenging Few-Shot Relation Classification
DocRED: A Large-Scale Document-Level Relation Extraction Dataset
Knowledge-Augmented Language Model and its Application to Unsupervised Named-Entity Recognition
Description-Based Zero-shot Fine-Grained Entity Typing
Zero-Shot Entity Linking by Reading Entity Descriptions
Multi-Level Matching and Aggregation Network for Few-Shot Relation Classification
Exploiting Entity BIO Tag Embeddings and Multi-task Learning for Relation Extraction with Imbalanced Data
Massively Multilingual Transfer for NER</p>

			</div>
			<hr class="post-end">
			<footer class="post-info">
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-feather"><path d="M20.24 12.24a6 6 0 0 0-8.49-8.49L5 10.5V19h8.5z"></path><line x1="16" y1="8" x2="2" y2="22"></line><line x1="17.5" y1="15" x2="9" y2="15"></line></svg>Hitchcock</p>
				<p>
					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://hitchcock717.github.io/tags/nlp">NLP</a></span>
				</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>5172 Words</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2020-03-24 08:00 &#43;0800</p>
			</footer>
		</article>
		<div class="post-nav thin">
			<a class="next-post" href="https://hitchcock717.github.io/posts/paperweekly-2/paperweekly-2/">
				<span class="post-nav-label"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left"><line x1="19" y1="12" x2="5" y2="12"></line><polyline points="12 19 5 12 12 5"></polyline></svg>&nbsp;Newer</span><br><span>PaperWeekly-2: nlp中的基础知识点整理(partI)</span>
			</a>
			<a class="prev-post" href="https://hitchcock717.github.io/posts/neo4j/neo4j/">
				<span class="post-nav-label">Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><br><span>CQL Query Language -- Neo4j</span>
			</a>
		</div>
		<div id="comments" class="thin">
</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2021 <a href="https://hitchcock717.github.io">Hitchcock</a> &#183; <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0</a></p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a> &#183; <a href="https://hitchcock717.github.io/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a>
		</p>
	</footer>



	<script src="https://hitchcock717.github.io/js/bundle.min.4a9a0ac3d2217822c7865b4161e6c2a71de1d70492264337755427898dd718f6.js" integrity="sha256-SpoKw9IheCLHhltBYebCpx3h1wSSJkM3dVQniY3XGPY=" crossorigin="anonymous"></script>
	

</body>

</html>
